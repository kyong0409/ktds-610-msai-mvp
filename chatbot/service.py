"""
ì±—ë´‡ ì„œë¹„ìŠ¤ ë¡œì§
"""
import streamlit as st
from typing import List, Dict
from config.settings import get_config

class ChatbotService:
    """ì±—ë´‡ ì„œë¹„ìŠ¤ í´ëž˜ìŠ¤"""

    def __init__(self):
        self.chat_config = get_config("chat")
        self.settings = st.session_state.get('chat_settings', {
            'temperature': 0.7,
            'max_tokens': 1000
        })

    def generate_response(self, query: str) -> str:
        """ì‚¬ìš©ìž ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        # ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        vector_db_data = st.session_state.get('vector_db', [])

        if not vector_db_data:
            return self._get_no_knowledge_response()

        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self._search_relevant_documents(query, vector_db_data)

        if relevant_docs:
            return self._generate_rag_response(query, relevant_docs, vector_db_data)
        else:
            return self._get_no_match_response(query, len(vector_db_data))

    def _search_relevant_documents(self, query: str, documents: List[Dict]) -> List[Dict]:
        """ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        relevant_docs = []
        query_lower = query.lower()
        query_keywords = query_lower.split()

        for doc in documents:
            content = doc.get("content", "").lower()
            filename = doc.get("filename", "").lower()

            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            content_matches = sum(1 for keyword in query_keywords if keyword in content)
            filename_matches = sum(1 for keyword in query_keywords if keyword in filename)

            total_score = content_matches * 2 + filename_matches  # ë‚´ìš©ì´ íŒŒì¼ëª…ë³´ë‹¤ ì¤‘ìš”

            if total_score > 0:
                doc_with_score = doc.copy()
                doc_with_score['relevance_score'] = total_score
                relevant_docs.append(doc_with_score)

        # ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        relevant_docs.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        return relevant_docs[:3]  # ìƒìœ„ 3ê°œ ë¬¸ì„œ

    def _generate_rag_response(self, query: str, relevant_docs: List[Dict], all_docs: List[Dict]) -> str:
        """RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        for i, doc in enumerate(relevant_docs[:2], 1):
            filename = doc.get("filename", f"ë¬¸ì„œ{i}")
            content = doc.get("content", "")[:800]  # 800ìž ì œí•œ
            quality_score = doc.get("quality_score", 0)
            context_parts.append(f"ðŸ“„ **{filename}** (í’ˆì§ˆì ìˆ˜: {quality_score}ì )\n{content}")

        context = "\n\n---\n\n".join(context_parts)

        # ì‘ë‹µ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜ - ì‹¤ì œë¡œëŠ” LLM API í˜¸ì¶œ)
        response = f"""ðŸ“š **ì €ìž¥ëœ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.**

**ì§ˆë¬¸:** {query}

**ë‹µë³€:**
{len(all_docs)}ê°œì˜ ì €ìž¥ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•œ ê²°ê³¼, ë‹¤ìŒê³¼ ê°™ì€ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:

{context}

**ðŸ’¡ ìš”ì•½:**
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ '{query}'ì— ëŒ€í•´ ë§ì”€ë“œë¦¬ë©´, ì €ìž¥ëœ ë¬¸ì„œë“¤ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ ìžˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!

---
ðŸ“Š **ê²€ìƒ‰ ê²°ê³¼:** {len(relevant_docs)}ê°œ ë¬¸ì„œ ë§¤ì¹­ | ðŸ’¾ **ì „ì²´ ë¬¸ì„œ:** {len(all_docs)}ê°œ"""

        return response

    def _get_no_knowledge_response(self) -> str:
        """ì§€ì‹ì´ ì—†ì„ ë•Œì˜ ì‘ë‹µ"""
        return """ðŸ¤” **ì•„ì§ ì €ìž¥ëœ ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤.**

í˜„ìž¬ í•™ìŠµí•œ ë¬¸ì„œê°€ ì—†ì–´ì„œ êµ¬ì²´ì ì¸ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤.

**ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê¶Œìž¥ë“œë¦½ë‹ˆë‹¤:**
1. ðŸ“š **ì§€ì‹ë“±ë¡** ë©”ë‰´ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì—…ë¡œë“œ
2. ðŸ¤– AI ë¶„ì„ì„ í†µí•œ ë¬¸ì„œ ë³´ì™„
3. ðŸ’¾ VectorDBì— ì €ìž¥

ë¬¸ì„œë¥¼ ë“±ë¡í•˜ì‹  í›„ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤! ðŸ˜Š"""

    def _get_no_match_response(self, query: str, total_docs: int) -> str:
        """ë§¤ì¹­ë˜ëŠ” ë¬¸ì„œê°€ ì—†ì„ ë•Œì˜ ì‘ë‹µ"""
        return f"""ðŸ” **'{query}'ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.**

í˜„ìž¬ {total_docs}ê°œì˜ ë¬¸ì„œê°€ ì €ìž¥ë˜ì–´ ìžˆì§€ë§Œ, ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.

**ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:**
- ðŸ”„ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸ ë³€ê²½
- ðŸ“š ê´€ë ¨ëœ ìƒˆë¡œìš´ ë¬¸ì„œ ì—…ë¡œë“œ
- ðŸ’¬ ë” êµ¬ì²´ì ì´ê±°ë‚˜ ì¼ë°˜ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ìž¬ì‹œë„

**ì˜ˆì‹œ ì§ˆë¬¸:**
- "ë¬¸ì„œì—ì„œ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?"
- "ë“±ë¡ëœ ë¬¸ì„œë“¤ì˜ ìš”ì•½ì„ ì•Œë ¤ì£¼ì„¸ìš”"
- "[íŠ¹ì • í‚¤ì›Œë“œ]ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"

ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”! ðŸ˜Š"""

    def get_chat_statistics(self) -> Dict:
        """ì±„íŒ… í†µê³„ ì •ë³´"""
        chat_history = st.session_state.get('chat_history', [])
        return {
            'total_messages': len(chat_history),
            'user_messages': len([msg for msg in chat_history if msg.get('role') == 'user']),
            'assistant_messages': len([msg for msg in chat_history if msg.get('role') == 'assistant']),
            'available_documents': len(st.session_state.get('vector_db', []))
        }